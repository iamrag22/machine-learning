{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions  2\n",
      "Shape  torch.Size([2, 3])\n",
      "Number of el  6\n",
      "1\n",
      "torch.Size([3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Tensor attributes\n",
    "# Most important are rank and shape\n",
    "a = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "print(\"Dimensions \", a.dim())\n",
    "print(\"Shape \", a.shape)\n",
    "print(\"Number of el \", a.numel())\n",
    "\n",
    "\n",
    "# For a specific axis\n",
    "print(a[0].dim())\n",
    "print(a[0].shape)\n",
    "print(a[0].numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 1\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]]) \n",
      "\n",
      "Option 2\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32) \n",
      "\n",
      "Option 3\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32) \n",
      "\n",
      "After update\n",
      "  tensor([[1, 2, 5],\n",
      "        [4, 5, 6]], dtype=torch.int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Tensor\n",
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "# Option1\n",
    "t1 = torch.Tensor(a)\n",
    "print(\"Option 1\\n\", t1, \"\\n\")\n",
    "\n",
    "# Option2 : \n",
    "# Automatic type inference\n",
    "t2 = torch.tensor(a)\n",
    "print(\"Option 2\\n\", t2, \"\\n\")\n",
    "\n",
    "# Option3:\n",
    "# Automatic type inference\n",
    "# Deep copy of numpy array a\n",
    "t3 = torch.as_tensor(a)\n",
    "print(\"Option 3\\n\", t3, \"\\n\")\n",
    "\n",
    "a[0][2]  = 5  # t3 is updated\n",
    "print(\"After update\\n \", t3, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]) \n",
      " tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "New ones \n",
      " tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Other Tensor creations\n",
    "a = torch.ones((3,4), dtype = torch.float32)\n",
    "b = torch.zeros((3,4))\n",
    "print(a,\"\\n\", b)\n",
    "\n",
    "# Using the same data type as existing tensor using new_ones()\n",
    "c = a.new_ones((5,6))\n",
    "print(\"New ones \\n\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor t \n",
      " tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n",
      "t1 \n",
      "  tensor([[1, 1, 1, 1, 2, 2],\n",
      "        [2, 2, 3, 3, 3, 3]])\n",
      "t2 \n",
      "  tensor([[[1, 1],\n",
      "         [1, 1],\n",
      "         [2, 2]],\n",
      "\n",
      "        [[2, 2],\n",
      "         [3, 3],\n",
      "         [3, 3]]]) 3\n",
      "t3 \n",
      " tensor([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3])\n",
      "tensor([[[1, 1, 1, 1],\n",
      "         [2, 2, 2, 2],\n",
      "         [3, 3, 3, 3]]]) torch.Size([1, 3, 4])\n",
      "Flattened tensor \n",
      " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Concat along zero dimension \n",
      " tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [1, 2],\n",
      "        [3, 4]])\n",
      "Concat along 1st dimension \n",
      " tensor([[1, 2, 1, 2],\n",
      "        [3, 4, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor Modification Operations\n",
    "# 1.reshape()\n",
    "# 2.view() . Similar to reshape but works only on contigous shapes\n",
    "# 3.squeeze()\n",
    "# 4.unsqueeze()\n",
    "# 5.flatten()\n",
    "# 6.cat()\n",
    "# 7. permute()\n",
    "\n",
    "\n",
    "# Reshape Operations\n",
    "# Org shape : 3x4\n",
    "t = torch.tensor([[1,1,1,1], [2,2,2,2], [3,3,3,3]])\n",
    "print(\"Original tensor t \\n\", t)\n",
    "\n",
    "# Change the shape but keep the dimensions same\n",
    "t1 = t.reshape((2,6))\n",
    "print(\"t1 \\n \", t1)\n",
    "\n",
    "# Change the shape and change the dimensions to 3\n",
    "t2 = t.reshape((2,3,2))\n",
    "print(\"t2 \\n \", t2, t2.dim())\n",
    "\n",
    "\n",
    "\n",
    "# Concat\n",
    "t6 = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]])\n",
    "t7 = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]])\n",
    "\n",
    "t8 = torch.cat((t6,t7), dim=0)\n",
    "print(\"Concat along zero dimension \\n\", t8)\n",
    "\n",
    "t9 = torch.cat((t6,t7), dim=1)\n",
    "print(\"Concat along 1st dimension \\n\", t9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " orig tensor \n",
      "  tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n",
      "\n",
      " Tensor flattened at dim 0  \n",
      " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      " Tensor flattened at dim 1 \n",
      " tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Flatten\n",
    "# This operation flattens an nd tensor to 1 dimension\n",
    "t = torch.ones(3,4).reshape(2,3,2)\n",
    "print(\"\\n orig tensor \\n \", t)\n",
    "\n",
    "t5 = t.flatten()# defaults to 0 as starting dimension to flatten\n",
    "print(\"\\n Tensor flattened at dim 0  \\n\", t5) # One row of all 1\n",
    "\n",
    "t6 = t.flatten(1)\n",
    "print(\"\\n Tensor flattened at dim 1 \\n\", t6)  # 2 rows of all 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Orginal tensor t \n",
      " tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n",
      "\n",
      " t3 \n",
      " tensor([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3])\n",
      "\n",
      " t4 \n",
      "  tensor([[[1, 1, 1, 1],\n",
      "         [2, 2, 2, 2],\n",
      "         [3, 3, 3, 3]]]) torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Squeeze\n",
    "# This removes all the len(1) dimensions\n",
    "# Does not require dimension as parameter\n",
    "# Wont have any impact on len>1 dimensions\n",
    "t = torch.tensor([[1,1,1,1], [2,2,2,2], [3,3,3,3]])\n",
    "print(\"\\n Orginal tensor t \\n\", t)\n",
    "\n",
    "t3 = t.reshape((1,12)).squeeze()\n",
    "print(\"\\n t3 \\n\", t3)\n",
    "\n",
    "# Unsqueeze\n",
    "# this adds a dimension along the specified axis\n",
    "t4 = t.unsqueeze(dim=0)  # Transforms (3,4) -> (1,3,4)\n",
    "print(\"\\n t4 \\n \", t4, t4.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element wise multiplication \n",
      "  tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 12., 22.]])\n",
      "Element wise addition \n",
      "  tensor([[ 4.,  5.,  6.],\n",
      "        [ 7.,  9., 14.]])\n",
      "Sum result \n",
      "  tensor(27.)\n",
      "Axis row result dim 0 \n",
      "  tensor([ 5.,  8., 14.])\n",
      "Axis row result dim 1 \n",
      "  tensor([ 6., 21.])\n",
      "\n",
      " Condition result \n",
      " tensor([[ True,  True,  True],\n",
      "        [ True,  True, False]])\n",
      "\n",
      " Mean \n",
      " tensor(5.1111)\n",
      "\n",
      " Mean \n",
      " 5.111111164093018\n",
      "\n",
      " Max el \n",
      " tensor(8)\n",
      "\n",
      " Max el for a given axis \n",
      " tensor([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Broadcast\n",
    "# Key Concept: Broadcast happens to match shapes\n",
    "# Eg: Tensor + 2 => In this case 2 is reshaped to a tensor of 2's of the same shape as Tensor\n",
    "\n",
    "a = torch.tensor([[1,2,3], [4,6,11]], dtype = torch.float32)\n",
    "mul_result = a*2\n",
    "print(\"Element wise multiplication \\n \", mul_result)\n",
    "\n",
    "add_result = a+3\n",
    "print(\"Element wise addition \\n \", add_result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Single Tensor Operation\n",
    "\n",
    "# Sum all elements\n",
    "sum_result = a.sum()\n",
    "print(\"Sum result \\n \",sum_result)\n",
    "\n",
    "# Sum along a given axis\n",
    "col_sum_result = torch.sum(a, dim=0) # col sum\n",
    "print(\"Axis row result dim 0 \\n \", col_sum_result)  #[5,8,14]\n",
    "\n",
    "row_sum_result = torch.sum(a, dim=1) # Row sum\n",
    "print(\"Axis row result dim 1 \\n \", row_sum_result)  #[[6], [21]]\n",
    "\n",
    "\n",
    "# Check conditions\n",
    "condition_result = a.le(8)\n",
    "print(\"\\n Condition result \\n\", condition_result)\n",
    "\n",
    "\n",
    "foo = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,10]\n",
    "], dtype = torch.float32)\n",
    "\n",
    "# Mean\n",
    "print(\"\\n Mean \\n\", foo.mean())  # Tensor(5)\n",
    "# item() returns the scalar value as a number instead of tensor\n",
    "print(\"\\n Mean \\n\", foo.mean().item())  # 5\n",
    "\n",
    "# Arg max returns the index of max val\n",
    "print(\"\\n Max el \\n\", foo.argmax())\n",
    "print(\"\\n Max el for a given axis \\n\", a.argmax(dim=1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " List comprehension \n",
      " tensor([0, 1, 0])\n",
      " \n",
      " User defined function \n",
      " tensor([11, 12, 13])\n"
     ]
    }
   ],
   "source": [
    "foo = torch.tensor([1,2,3])\n",
    "\n",
    "# List comprehension\n",
    "bar = torch.tensor([1 if i%2==0 else 0 for i in foo])\n",
    "print(\" \\n List comprehension \\n\", bar)\n",
    "# User defined function\n",
    "def add_10(x):\n",
    "    return x+10\n",
    "\n",
    "baz = torch.tensor([add_10(i) for i in foo])\n",
    "print(\" \\n User defined function \\n\", baz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "tensor([[[1, 2, 3, 4, 5, 6, 7, 8]]]) 3\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8]) 1\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8]]) 2\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8]]) 2\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([ [1,2,3,4], [5,6,7,8]])\n",
    "print(a.shape)\n",
    "a1 = a.reshape((1,1,8))\n",
    "print(a1, a1.dim())\n",
    "b = a1.squeeze()\n",
    "print(b,  b.dim())\n",
    "c = b.unsqueeze(dim=-2)\n",
    "d = b.unsqueeze(dim=0)\n",
    "print(c, c.dim())\n",
    "print(d, d.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org tensor \n",
      " tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "Flattened tensor \n",
      " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]) torch.Size([12])\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.ones(3,4)\n",
    "print(\"Org tensor \\n\", t5)\n",
    "t6 = torch.flatten(t5)\n",
    "print(\"Flattened tensor \\n\", t6,t6.shape)\n",
    "\n",
    "t7 = t5.reshape((2,3,2))\n",
    "print(t7)\n",
    "print(t7.flatten(0))\n",
    "print(t7.flatten(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 1, 1, 1],\n",
      "         [1, 1, 1, 1],\n",
      "         [1, 1, 1, 1],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[2, 2, 2, 2],\n",
      "         [2, 2, 2, 2],\n",
      "         [2, 2, 2, 2],\n",
      "         [2, 2, 2, 2]],\n",
      "\n",
      "        [[3, 3, 3, 3],\n",
      "         [3, 3, 3, 3],\n",
      "         [3, 3, 3, 3],\n",
      "         [3, 3, 3, 3]]]) torch.Size([3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Flatten\n",
    "# torch.flatten(tensor, start_dim=dim, -1) => Provide the starting dimension from where flatten should occur\n",
    "# This is very useful in CNN output to FCN layers\n",
    "# If we have [batch_size, channels, width, height], then we can flatten from channel\n",
    "t1 = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1]\n",
    "])\n",
    "\n",
    "t2 = torch.tensor([\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2]\n",
    "])\n",
    "\n",
    "t3 = torch.tensor([\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3]\n",
    "])\n",
    "\n",
    "t4 = torch.stack((t1,t2,t3),dim=0)\n",
    "print(t4, t4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[3, 4]\n",
      "[5, 6]\n",
      "[7, 8]\n",
      "[9, 10]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for i in range(0, len(a), 2):\n",
    "    print(a[i:i+2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim 0 add axis  tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "Dim 1 add axis \n",
      " tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(\"Dim 0 add axis \", t.unsqueeze(dim=0))\n",
    "print(\"Dim 1 add axis \\n\", t.unsqueeze(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3],\n",
      "        [11, 12, 13]]) torch.Size([2, 3])\n",
      "tensor([[20, 30, 40],\n",
      "        [21, 31, 41]])\n",
      "\n",
      " Concat along dim  0 \n",
      "  tensor([[ 1,  2,  3],\n",
      "        [11, 12, 13],\n",
      "        [20, 30, 40],\n",
      "        [21, 31, 41]]) torch.Size([4, 3])\n",
      "Concat along dim  1\n",
      "  tensor([[ 1,  2,  3, 20, 30, 40],\n",
      "        [11, 12, 13, 21, 31, 41]]) torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1,2,3],[11,12,13]])\n",
    "t2 = torch.tensor([[20,30,40],[21,31,41]])\n",
    "\n",
    "print(t1, t1.shape)\n",
    "print(t2)\n",
    "\n",
    "\n",
    "t4 = torch.cat((t1,t2), dim=0)\n",
    "print(\"\\n Concat along dim  0 \\n \", t4, t4.shape)\n",
    "\n",
    "t5 = torch.cat((t1,t2), dim=1)\n",
    "print(\"Concat along dim  1\\n \", t5, t5.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 2, 3]])\n",
      "tensor([[1, 4, 7],\n",
      "        [2, 5, 2],\n",
      "        [3, 6, 3]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1,2,3])\n",
    "t2 = torch.tensor([4,5,6])\n",
    "t3 = torch.tensor([7,2,3])\n",
    "print(torch.cat((t1,t2,t3), dim=0))\n",
    "print(torch.stack((t1,t2,t3), dim=0))\n",
    "print(torch.stack((t1,t2,t3), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
