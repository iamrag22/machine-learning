{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict,namedtuple\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949])\n",
      "tensor([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009])\n",
      "Training Dataset size 60000\n",
      "Testing Dataset size 10000\n"
     ]
    }
   ],
   "source": [
    "# Download data for FashionMNIST\n",
    "\n",
    "# Training\n",
    "train_dataset = datasets.MNIST(\n",
    "    \"./data\",\n",
    "    download = True,\n",
    "    train = True,\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "# Sanity Testing\n",
    "# Check the distribution of labels in training set\n",
    "print(train_dataset.targets.bincount())\n",
    "\n",
    "# Each batch has [images, labels]. the count of images/labels is the same as batch size\n",
    "train_batch_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 50,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# Test\n",
    "test_dataset = datasets.MNIST(\n",
    "    \"./data\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "# Sanity Testing\n",
    "# Check the distribution of labels in test set\n",
    "print(test_dataset.targets.bincount())\n",
    "\n",
    "test_batch_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = 50\n",
    ")\n",
    "\n",
    "\n",
    "# Training Dataset size\n",
    "print(\"Training Dataset size\", len(train_batch_dataloader.dataset))\n",
    "\n",
    "# Testing Dataset size\n",
    "print(\"Testing Dataset size\", len(test_batch_dataloader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "torch.Size([50, 1, 28, 28])\n",
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "train_batch = next(iter(train_batch_dataloader))\n",
    "print(train_batch[0].shape)\n",
    "\n",
    "print(len(train_batch_dataloader.dataset), len(test_batch_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTCNN(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "class MNISTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5)\n",
    "        self.linear_size = None\n",
    "        X = torch.rand(28,28).reshape(-1, 1, 28,28)\n",
    "        self.convs(X)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = self.linear_size, out_features = 120)\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        self.out = nn.Linear(in_features = 60, out_features = 10)\n",
    "        \n",
    "    def convs(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X,  kernel_size = 2, stride = 2)\n",
    "        \n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X,  kernel_size = 2, stride = 2)\n",
    "        \n",
    "        X =  X.flatten(1,-1)\n",
    "        \n",
    "        if self.linear_size is None:\n",
    "            self.linear_size = X.shape[1]\n",
    "        \n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = self.convs(X)\n",
    "        \n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        \n",
    "        X = self.out(X)\n",
    "        \n",
    "        return X.to(device)\n",
    "\n",
    "network = MNISTCNN()\n",
    "network = network.to(device)\n",
    "print(network)\n",
    "print(network.linear_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        # params is an ordered dict\n",
    "        keys = params.keys()\n",
    "        \n",
    "        values =params.values()\n",
    "        \n",
    "        Run = namedtuple('Run', keys)\n",
    "        \n",
    "        Runs = []\n",
    "        \n",
    "        for param_value_combination_tuple in product(*values):\n",
    "            run = Run(*param_value_combination_tuple)\n",
    "            Runs.append(run)\n",
    "        \n",
    "        return Runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Manager to manage Run/Epoch level operations and logging to TensorBoard\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        self.run =  None\n",
    "        self.network = None\n",
    "        self.tb = None\n",
    "        \n",
    "        self.train_batch_dataloader = None\n",
    "        self.test_batch_dataloader = None\n",
    "        \n",
    "        self.epoch_id = 0\n",
    "        self.correct_predictions = 0\n",
    "        self.total_loss=0.0\n",
    "        \n",
    "    def run_start(self, run, network, train_batch_dataloader, test_batch_dataloader):\n",
    "        self.run = run\n",
    "        self.tb = SummaryWriter(comment=f\"MNIST-{run}\")\n",
    "        self.network = network\n",
    "        \n",
    "        self.train_batch_dataloader = train_batch_dataloader\n",
    "        self.test_batch_dataloader = test_batch_dataloader\n",
    "        \n",
    "        self.epoch_id = 0\n",
    "    \n",
    "    def run_end(self):\n",
    "        self.tb.close()\n",
    "    \n",
    "    def epoch_start(self):\n",
    "        self.correct_predictions = 0\n",
    "        self.total_loss=0.0\n",
    "        \n",
    "    \n",
    "    def epoch_end(self):\n",
    "        accuracy = 100*(self.correct_predictions/len(self.train_batch_dataloader.dataset))\n",
    "        \n",
    "        self.tb.add_scalar(\"Training Accuracy\", accuracy,self.epoch_id)\n",
    "        self.tb.add_scalar(\"Training Loss\", self.total_loss, self.epoch_id)\n",
    "        \n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(f\"{name}.grad\", param.grad, self.epoch_id)\n",
    "        \n",
    "        self.total_loss=0.0\n",
    "        self.epoch_id+=1\n",
    "        \n",
    "    # This will be called per batch\n",
    "    def track_correct_predictions(self, predictions, actual):\n",
    "        correct_predictions = self.get_correct_predictions(predictions, actual)\n",
    "        self.correct_predictions+= correct_predictions\n",
    "    \n",
    "    # This will be called per batch\n",
    "    def track_total_loss(self,loss):\n",
    "        self.total_loss+=loss\n",
    "    \n",
    "    def get_correct_predictions(self, predictions, actual):\n",
    "        predictions = predictions.argmax(dim=1)\n",
    "        # actual = actual.argmax(dim=1)\n",
    "        \n",
    "        matches = predictions.eq(actual).sum().item()\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "    def record_validation_stats(self, accuracy, loss, epoch):\n",
    "        self.tb.add_scalar(\"Validation Accuracy: \", accuracy, epoch)\n",
    "        self.tb.add_scalar(\"Validation Loss: \", loss, epoch)\n",
    "        \n",
    "rm = RunManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy  97.71\n",
      "Test Accuracy  98.53\n",
      "Test Accuracy  97.61\n",
      "Test Accuracy  98.63\n"
     ]
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [0.001,0.01],\n",
    "    batch_size = [100, 1000]\n",
    ")\n",
    "\n",
    "runs = RunBuilder.get_runs(params)\n",
    "rm = RunManager()\n",
    "EPOCHS = 3\n",
    "\n",
    "for run in runs:\n",
    "    optimizer = optim.Adam(network.parameters(), lr =run.lr)\n",
    "    train_batch_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size = run.batch_size\n",
    "    )\n",
    "    test_batch_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size = run.batch_size\n",
    "    )    \n",
    "    rm.run_start(run, network, train_batch_loader, test_batch_loader)\n",
    "    for epoch in range(EPOCHS):\n",
    "        rm.epoch_start()\n",
    "        \n",
    "        for train_batch in train_batch_loader:\n",
    "            train_images, train_labels = train_batch\n",
    "            \n",
    "            train_images = train_images.reshape(run.batch_size, 1, 28,28)\n",
    "            train_images = train_images.to(device)\n",
    "            \n",
    "            train_labels = train_labels.to(device)\n",
    "            \n",
    "            network.zero_grad()\n",
    "            \n",
    "            predicted = network(train_images)\n",
    "            loss = F.cross_entropy(predicted, train_labels)\n",
    "            \n",
    "            rm.track_total_loss(loss.item())\n",
    "            rm.track_correct_predictions(predicted, train_labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        rm.epoch_end()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct_predictions = 0\n",
    "        total_loss = 0.0\n",
    "        for test_batch in test_batch_loader:\n",
    "            test_images, test_labels = test_batch\n",
    "            test_images = test_images.to(device)\n",
    "            test_labels = test_labels.to(device)\n",
    "            \n",
    "            predicted = network(test_images)\n",
    "            \n",
    "            correct_predictions += rm.get_correct_predictions(predicted, test_labels)\n",
    "            \n",
    "            loss = F.cross_entropy(predicted, test_labels).item()\n",
    "            total_loss += loss\n",
    "            \n",
    "        test_accuracy = 100*(correct_predictions/len(test_batch_loader.dataset))\n",
    "        print(\"Test Accuracy \", test_accuracy)\n",
    "        rm.record_validation_stats(test_accuracy, total_loss, epoch)\n",
    "    rm.run_end()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('pytorchenv': conda)",
   "language": "python",
   "name": "python38264bitpytorchenvcondaa1d2a31854e0434a85965068b8c72b15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
